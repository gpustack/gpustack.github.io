
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://docs.gpustack.ai/2.0/performance-lab/deepseek-v3.2/h200/">
      
      
        <link rel="prev" href="../../deepseek-r1/h200/">
      
      
        <link rel="next" href="../../qwen3-8b/910b/">
      
      
      <link rel="icon" href="../../../assets/logo.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.30">
    
    
      
        <title>H200 - GPUStack</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.3cba04c6.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
      <link rel="stylesheet" href="https://unpkg.com/katex@0/dist/katex.min.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
   <link href="../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#optimizing-deepseek-v32-throughput-on-nvidia-h200-gpus" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
          <aside class="md-banner md-banner--warning">
            <div class="md-banner__inner md-grid md-typeset">
              
  You're not viewing the latest version.
  <a href="../../../..">
    <strong>Click here to go to latest.</strong>
  </a>

            </div>
            <script>var el=document.querySelector("[data-md-component=outdated]"),outdated=__md_get("__outdated",sessionStorage);!0===outdated&&el&&(el.hidden=!1)</script>
          </aside>
        
      </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="GPUStack" class="md-header__button md-logo" aria-label="GPUStack" data-md-component="logo">
      
  <img src="../../../assets/logo-white.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            GPUStack
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              H200
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="orange"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2a7 7 0 0 0-7 7c0 2.38 1.19 4.47 3 5.74V17a1 1 0 0 0 1 1h6a1 1 0 0 0 1-1v-2.26c1.81-1.27 3-3.36 3-5.74a7 7 0 0 0-7-7M9 21a1 1 0 0 0 1 1h4a1 1 0 0 0 1-1v-1H9v1Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="light-blue" data-md-color-accent="orange"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2a7 7 0 0 1 7 7c0 2.38-1.19 4.47-3 5.74V17a1 1 0 0 1-1 1H9a1 1 0 0 1-1-1v-2.26C6.19 13.47 5 11.38 5 9a7 7 0 0 1 7-7M9 21v-1h6v1a1 1 0 0 1-1 1h-4a1 1 0 0 1-1-1m3-17a5 5 0 0 0-5 5c0 2.05 1.23 3.81 3 4.58V16h4v-2.42c1.77-.77 3-2.53 3-4.58a5 5 0 0 0-5-5Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/gpustack/gpustack" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../overview/" class="md-tabs__link">
          
  
    
  
  Home

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../overview/" class="md-tabs__link">
          
  
    
  
  Inference Performance Lab

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="GPUStack" class="md-nav__button md-logo" aria-label="GPUStack" data-md-component="logo">
      
  <img src="../../../assets/logo-white.png" alt="logo">

    </a>
    GPUStack
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/gpustack/gpustack" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Home
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Home
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../quickstart/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quickstart
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_3" >
        
          
          <label class="md-nav__link" for="__nav_1_3" id="__nav_1_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Installation
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_3">
            <span class="md-nav__icon md-icon"></span>
            Installation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../installation/requirements/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Requirements
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../installation/installation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Installation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../installation/air-gapped/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Air-Gapped Installation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../installation/uninstallation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Uninstallation
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../upgrade/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Upgrade
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../migration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Migration
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_6" >
        
          
          <label class="md-nav__link" for="__nav_1_6" id="__nav_1_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    User Guide
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_6">
            <span class="md-nav__icon md-icon"></span>
            User Guide
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_6_1" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../user-guide/playground/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Playground
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_1_6_1" id="__nav_1_6_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_1_6_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_6_1">
            <span class="md-nav__icon md-icon"></span>
            Playground
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../user-guide/playground/chat/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Chat
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../user-guide/playground/image/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Image
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../user-guide/playground/audio/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../user-guide/playground/embedding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Embedding
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../user-guide/playground/rerank/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Rerank
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../user-guide/model-catalog/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Catalog
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../user-guide/model-deployment-management/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Deployment Management
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../user-guide/inference-backend-management/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Inference Backend Management
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../user-guide/built-in-inference-backends/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Built-in Inference Backends
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../user-guide/compatibility-check/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Compatibility Check
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../user-guide/model-file-management/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model File management
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../user-guide/cluster-management/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cluster Management
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../user-guide/cloud-credential-management/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cloud Credential Management
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../user-guide/openai-compatible-apis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    OpenAI Compatible APIs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../user-guide/image-generation-apis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Image Generation APIs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../user-guide/rerank-api/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Rerank API
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../user-guide/api-key-management/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API Key Management
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../user-guide/user-management/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    User Management
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../user-guide/sso/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single Sign-On (SSO) Authentication
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../user-guide/observability/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Observability
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_7" >
        
          
          <label class="md-nav__link" for="__nav_1_7" id="__nav_1_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Using Models
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_7">
            <span class="md-nav__icon md-icon"></span>
            Using Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-models/using-large-language-models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using Large Language Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-models/using-vision-language-models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using Vision Language Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-models/using-embedding-models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using Embedding Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-models/using-reranker-models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using Reranker Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-models/using-image-generation-models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using Image Generation Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-models/using-audio-models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using Audio Models
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_8" >
        
          
          <label class="md-nav__link" for="__nav_1_8" id="__nav_1_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_8">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/running-deepseek-r1-671b-with-distributed-vllm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Running DeepSeek R1 671B with Distributed vLLM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/running-deepseek-r1-671b-with-distributed-ascend-mindie/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Running DeepSeek R1 671B with Distributed Ascend Mindie
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/inference-on-cpus/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Inference On CPUs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/inference-with-tool-calling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Inference with Tool Calling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/using-custom-backends/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using Custom Inference Backend
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/adding-gpucluster-using-digitalocean/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Adding a GPU Cluster Using DigitalOcean
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/adding-gpucluster-using-kubernetes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Adding a GPU Cluster Using Kubernetes
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_9" >
        
          
          <label class="md-nav__link" for="__nav_1_9" id="__nav_1_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Integrations
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_9">
            <span class="md-nav__icon md-icon"></span>
            Integrations
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../integrations/openai-compatible-apis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    OpenAI Compatible APIs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../integrations/integrate-with-dify/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Integrate with Dify
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../integrations/integrate-with-ragflow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Integrate with RAGFlow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../integrations/integrate-with-cherrystudio/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Integrate with CherryStudio
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../architecture/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Architecture
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../scheduler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Scheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../troubleshooting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Troubleshooting
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../faq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FAQ
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../api-reference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API Reference
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_15" >
        
          
          <label class="md-nav__link" for="__nav_1_15" id="__nav_1_15_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    CLI Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_15_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_15">
            <span class="md-nav__icon md-icon"></span>
            CLI Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cli-reference/start/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Start
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cli-reference/download-tools/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Download Tools
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cli-reference/reload-config/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reload Config
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cli-reference/list-images/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    List Images
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cli-reference/save-images/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Save Images
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cli-reference/copy-images/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Copy Images
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../environment-variables/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Environment Variables
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Inference Performance Lab
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Inference Performance Lab
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Optimizing Throughput
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Optimizing Throughput
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_2_1" id="__nav_2_2_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    GLM-4.5-Air
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_1">
            <span class="md-nav__icon md-icon"></span>
            GLM-4.5-Air
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../glm-4.5-air/a100/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A100
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../glm-4.5-air/h100/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    H100
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2_2" id="__nav_2_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    GLM-4.x
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_2">
            <span class="md-nav__icon md-icon"></span>
            GLM-4.x
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../glm-4.x/a100/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A100
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../glm-4.x/h100/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    H100
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../glm-4.x/h200/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    H200
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_2_3" id="__nav_2_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    GPT-OSS-20B
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_3">
            <span class="md-nav__icon md-icon"></span>
            GPT-OSS-20B
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../gpt-oss-20b/a100/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A100
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../gpt-oss-20b/h100/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    H100
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2_4" >
        
          
          <label class="md-nav__link" for="__nav_2_2_4" id="__nav_2_2_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    GPT-OSS-120B
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_4">
            <span class="md-nav__icon md-icon"></span>
            GPT-OSS-120B
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../gpt-oss-120b/a100/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A100
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../gpt-oss-120b/h100/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    H100
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2_5" >
        
          
          <label class="md-nav__link" for="__nav_2_2_5" id="__nav_2_2_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    DeepSeek-R1
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_5">
            <span class="md-nav__icon md-icon"></span>
            DeepSeek-R1
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deepseek-r1/h200/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    H200
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2_6" checked>
        
          
          <label class="md-nav__link" for="__nav_2_2_6" id="__nav_2_2_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    DeepSeek-V3.2
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_2_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_2_6">
            <span class="md-nav__icon md-icon"></span>
            DeepSeek-V3.2
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    H200
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    H200
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#optimization-objective" class="md-nav__link">
    <span class="md-ellipsis">
      Optimization Objective
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#experimental-setup" class="md-nav__link">
    <span class="md-ellipsis">
      Experimental Setup
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Experimental Setup">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model" class="md-nav__link">
    <span class="md-ellipsis">
      Model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hardware" class="md-nav__link">
    <span class="md-ellipsis">
      Hardware
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#engine-version" class="md-nav__link">
    <span class="md-ellipsis">
      Engine Version
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#benchmark-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Benchmark Dataset
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#benchmark-script" class="md-nav__link">
    <span class="md-ellipsis">
      Benchmark Script
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#experiment-results" class="md-nav__link">
    <span class="md-ellipsis">
      Experiment Results
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Experiment Results">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-baseline-of-the-inference-engine" class="md-nav__link">
    <span class="md-ellipsis">
      1. Baseline of the Inference Engine
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-optimizing-vllm" class="md-nav__link">
    <span class="md-ellipsis">
      2. Optimizing vLLM
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Optimizing vLLM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parallelism-dpep" class="md-nav__link">
    <span class="md-ellipsis">
      Parallelism: DP+EP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallelism-dcp" class="md-nav__link">
    <span class="md-ellipsis">
      Parallelism: DCP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mtp" class="md-nav__link">
    <span class="md-ellipsis">
      MTP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#turn-off-deepgemm-in-vllm" class="md-nav__link">
    <span class="md-ellipsis">
      Turn off DeepGEMM in vLLM
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#enable-tool-call-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      Enable Tool Call Configuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#context-length-adjustment" class="md-nav__link">
    <span class="md-ellipsis">
      Context Length Adjustment
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#attention-backend-cutlass_mla" class="md-nav__link">
    <span class="md-ellipsis">
      Attention Backend: CUTLASS_MLA
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#attention-backend-flashmla" class="md-nav__link">
    <span class="md-ellipsis">
      Attention Backend: FLASHMLA
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#attention-backend-triton_mla" class="md-nav__link">
    <span class="md-ellipsis">
      Attention Backend: TRITON_MLA
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-optimizing-sglang" class="md-nav__link">
    <span class="md-ellipsis">
      3. Optimizing SGLang
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Optimizing SGLang">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parallelism-tpdp-attention" class="md-nav__link">
    <span class="md-ellipsis">
      Parallelism: TP+DP Attention
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallelism-tpdpdp-attention" class="md-nav__link">
    <span class="md-ellipsis">
      Parallelism: TP+DP+DP Attention
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallelism-tpdpdp-attentionep" class="md-nav__link">
    <span class="md-ellipsis">
      Parallelism: TP+DP+DP Attention+EP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mtp_1" class="md-nav__link">
    <span class="md-ellipsis">
      MTP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#turn-off-deepgemm" class="md-nav__link">
    <span class="md-ellipsis">
      Turn off DeepGEMM
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#enable-tool-call-configuration_1" class="md-nav__link">
    <span class="md-ellipsis">
      Enable Tool Call Configuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#context-length-adjustment_1" class="md-nav__link">
    <span class="md-ellipsis">
      Context Length Adjustment
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kv-cache-dtype" class="md-nav__link">
    <span class="md-ellipsis">
      KV Cache DType
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#attention-backend-fa3-fa3" class="md-nav__link">
    <span class="md-ellipsis">
      Attention Backend: fa3 + fa3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#attention-backend-flashmla_sparse-flashmla_kv" class="md-nav__link">
    <span class="md-ellipsis">
      Attention Backend: flashmla_sparse + flashmla_kv
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-optimizing-tensorrt-llm" class="md-nav__link">
    <span class="md-ellipsis">
      4. Optimizing TensorRT-LLM
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. Optimizing TensorRT-LLM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parallelism-tpep" class="md-nav__link">
    <span class="md-ellipsis">
      Parallelism: TP+EP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#turn-off-deepgemm_1" class="md-nav__link">
    <span class="md-ellipsis">
      Turn off DeepGEMM
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary-of-optimization-options" class="md-nav__link">
    <span class="md-ellipsis">
      Summary of Optimization Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#other-benchmark-cases" class="md-nav__link">
    <span class="md-ellipsis">
      Other Benchmark Cases
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2_7" >
        
          
          <label class="md-nav__link" for="__nav_2_2_7" id="__nav_2_2_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Qwen3-8B
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_2_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_7">
            <span class="md-nav__icon md-icon"></span>
            Qwen3-8B
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../qwen3-8b/910b/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    910B
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2_8" >
        
          
          <label class="md-nav__link" for="__nav_2_2_8" id="__nav_2_2_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Qwen3-14B
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_2_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_8">
            <span class="md-nav__icon md-icon"></span>
            Qwen3-14B
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../qwen3-14b/a100/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A100
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../qwen3-14b/h100/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    H100
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2_9" >
        
          
          <label class="md-nav__link" for="__nav_2_2_9" id="__nav_2_2_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Qwen3-32B
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_2_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_9">
            <span class="md-nav__icon md-icon"></span>
            Qwen3-32B
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../qwen3-32b/a100/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A100
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../qwen3-32b/h100/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    H100
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2_10" >
        
          
          <label class="md-nav__link" for="__nav_2_2_10" id="__nav_2_2_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Qwen3-30B-A3B
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_2_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_10">
            <span class="md-nav__icon md-icon"></span>
            Qwen3-30B-A3B
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../qwen3-30b-a3b/910b/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    910B
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2_11" >
        
          
          <label class="md-nav__link" for="__nav_2_2_11" id="__nav_2_2_11_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Qwen3-235B-A22B
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_2_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_11">
            <span class="md-nav__icon md-icon"></span>
            Qwen3-235B-A22B
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../qwen3-235b-a22b/a100/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A100
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../qwen3-235b-a22b/h100/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    H100
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Optimizing Latency
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Optimizing Latency
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3_1" >
        
          
          <label class="md-nav__link" for="__nav_2_3_1" id="__nav_2_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Qwen3-8B
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3_1">
            <span class="md-nav__icon md-icon"></span>
            Qwen3-8B
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../qwen3-8b/h100-latency/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    H100
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4" >
        
          
          <label class="md-nav__link" for="__nav_2_4" id="__nav_2_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    References
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4">
            <span class="md-nav__icon md-icon"></span>
            References
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../references/the-impact-of-quantization-on-vllm-inference-performance/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    The Impact of Quantization on vLLM Inference Performance
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../references/evaluating-lmcache-prefill-acceleration-in-vllm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Evaluating LMCache Prefill Acceleration in vLLM
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#optimization-objective" class="md-nav__link">
    <span class="md-ellipsis">
      Optimization Objective
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#experimental-setup" class="md-nav__link">
    <span class="md-ellipsis">
      Experimental Setup
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Experimental Setup">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model" class="md-nav__link">
    <span class="md-ellipsis">
      Model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hardware" class="md-nav__link">
    <span class="md-ellipsis">
      Hardware
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#engine-version" class="md-nav__link">
    <span class="md-ellipsis">
      Engine Version
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#benchmark-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Benchmark Dataset
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#benchmark-script" class="md-nav__link">
    <span class="md-ellipsis">
      Benchmark Script
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#experiment-results" class="md-nav__link">
    <span class="md-ellipsis">
      Experiment Results
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Experiment Results">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-baseline-of-the-inference-engine" class="md-nav__link">
    <span class="md-ellipsis">
      1. Baseline of the Inference Engine
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-optimizing-vllm" class="md-nav__link">
    <span class="md-ellipsis">
      2. Optimizing vLLM
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Optimizing vLLM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parallelism-dpep" class="md-nav__link">
    <span class="md-ellipsis">
      Parallelism: DP+EP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallelism-dcp" class="md-nav__link">
    <span class="md-ellipsis">
      Parallelism: DCP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mtp" class="md-nav__link">
    <span class="md-ellipsis">
      MTP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#turn-off-deepgemm-in-vllm" class="md-nav__link">
    <span class="md-ellipsis">
      Turn off DeepGEMM in vLLM
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#enable-tool-call-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      Enable Tool Call Configuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#context-length-adjustment" class="md-nav__link">
    <span class="md-ellipsis">
      Context Length Adjustment
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#attention-backend-cutlass_mla" class="md-nav__link">
    <span class="md-ellipsis">
      Attention Backend: CUTLASS_MLA
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#attention-backend-flashmla" class="md-nav__link">
    <span class="md-ellipsis">
      Attention Backend: FLASHMLA
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#attention-backend-triton_mla" class="md-nav__link">
    <span class="md-ellipsis">
      Attention Backend: TRITON_MLA
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-optimizing-sglang" class="md-nav__link">
    <span class="md-ellipsis">
      3. Optimizing SGLang
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Optimizing SGLang">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parallelism-tpdp-attention" class="md-nav__link">
    <span class="md-ellipsis">
      Parallelism: TP+DP Attention
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallelism-tpdpdp-attention" class="md-nav__link">
    <span class="md-ellipsis">
      Parallelism: TP+DP+DP Attention
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parallelism-tpdpdp-attentionep" class="md-nav__link">
    <span class="md-ellipsis">
      Parallelism: TP+DP+DP Attention+EP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mtp_1" class="md-nav__link">
    <span class="md-ellipsis">
      MTP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#turn-off-deepgemm" class="md-nav__link">
    <span class="md-ellipsis">
      Turn off DeepGEMM
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#enable-tool-call-configuration_1" class="md-nav__link">
    <span class="md-ellipsis">
      Enable Tool Call Configuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#context-length-adjustment_1" class="md-nav__link">
    <span class="md-ellipsis">
      Context Length Adjustment
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kv-cache-dtype" class="md-nav__link">
    <span class="md-ellipsis">
      KV Cache DType
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#attention-backend-fa3-fa3" class="md-nav__link">
    <span class="md-ellipsis">
      Attention Backend: fa3 + fa3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#attention-backend-flashmla_sparse-flashmla_kv" class="md-nav__link">
    <span class="md-ellipsis">
      Attention Backend: flashmla_sparse + flashmla_kv
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-optimizing-tensorrt-llm" class="md-nav__link">
    <span class="md-ellipsis">
      4. Optimizing TensorRT-LLM
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. Optimizing TensorRT-LLM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parallelism-tpep" class="md-nav__link">
    <span class="md-ellipsis">
      Parallelism: TP+EP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#turn-off-deepgemm_1" class="md-nav__link">
    <span class="md-ellipsis">
      Turn off DeepGEMM
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary-of-optimization-options" class="md-nav__link">
    <span class="md-ellipsis">
      Summary of Optimization Options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#other-benchmark-cases" class="md-nav__link">
    <span class="md-ellipsis">
      Other Benchmark Cases
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/gpustack/gpustack/edit/main/docs/performance-lab/deepseek-v3.2/h200.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4v-2m10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1 2.1 2.1Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/gpustack/gpustack/raw/main/docs/performance-lab/deepseek-v3.2/h200.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.15 8.15 0 0 1-1.23-2Z"/></svg>
    </a>
  


<h1 id="optimizing-deepseek-v32-throughput-on-nvidia-h200-gpus">Optimizing DeepSeek-V3.2 Throughput on NVIDIA H200 GPUs</h1>
<h2 id="conclusion">Conclusion</h2>
<p><a class="glightbox" href="../../../assets/performance-lab/deepseek-v3.2-h200.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="DeepSeek-V3.2 H200 Throughput Optimization" src="../../../assets/performance-lab/deepseek-v3.2-h200.png" /></a>
Recommended configuration for optimizing throughput of DeepSeek-V3.2 on a single node with H200x8:</p>
<details class="tip" open="open">
<summary>Serving Command</summary>
<div class="highlight"><pre><span></span><code>python3<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span><span class="se">\</span>
--chat-template<span class="w"> </span>./tool_chat_template_deepseekv32.jinja<span class="w"> </span><span class="se">\</span>
--tp-size<span class="w"> </span><span class="m">8</span><span class="w"> </span>--dp-size<span class="w"> </span><span class="m">8</span><span class="w"> </span>--enable-dp-attention
--reasoning-parser<span class="w"> </span>deepseek-v3<span class="w"> </span><span class="se">\</span>
--tool-call-parser<span class="w"> </span>deepseekv32
</code></pre></div>
</details>
<p>Link for <a href="https://github.com/sgl-project/sglang/blob/main/examples/chat_template/tool_chat_template_deepseekv32.jinja">tool_chat_template_deepseekv32.jinja</a>. </p>
<p>Based on the below benchmarks, we recommend the above configuration for optimizing <strong>DeepSeek-V3.2</strong> throughput on <strong>8H200</strong>.</p>
<p><strong>Parallelism</strong> and <strong>Tool Call Configuration</strong> provide the largest performance gains and are therefore included in the recommended command. <strong>Context Length Adjustment</strong> can further improve throughput but is highly workload-dependent and should be tuned according to actual usage.
While <strong>Attention Backend</strong> optimizations show positive effects, their gains are relatively small and may vary across datasets, so they are not included in the default recommendation.</p>
<p>Comparison of benchmark results before and after optimization:</p>
<table>
<thead>
<tr>
<th>Benchmark Case</th>
<th>baseline (vLLM without any optimizations)</th>
<th>Optimized</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ShareGPT</strong></td>
<td>Total TPS: 5713.95<br>Mean TPOT(ms): 275.03</td>
<td>Total TPS: 8968.32 <span style="background-color:lightgreen;">(+56.95%)</span><br>Mean TPOT(ms): 203.05</td>
</tr>
<tr>
<td><strong>Short Prompt</strong></td>
<td>Total TPS: 10071.49<br>Mean TPOT(ms): 781.80</td>
<td>Total TPS: 18227.38 <span style="background-color:lightgreen;">(+80.98%)</span><br>Mean TPOT(ms): 776.55</td>
</tr>
<tr>
<td><strong>Medium Prompt</strong></td>
<td>Total TPS: 10925.59<br>Mean TPOT(ms): 354.59</td>
<td>Total TPS: 27712.54 <span style="background-color:lightgreen;">(+153.65%)</span><br>Mean TPOT(ms): 192.24</td>
</tr>
<tr>
<td><strong>Long Prompt</strong></td>
<td>Total TPS: 9974.26<br>Mean TPOT(ms): 226.74</td>
<td>Total TPS: 20545.67 <span style="background-color:lightgreen;">(+105.99%)</span><br>Mean TPOT(ms): 177.95</td>
</tr>
<tr>
<td><strong>Very Long Prompt</strong></td>
<td>Total TPS: 9709.27<br>Mean TPOT(ms): 472.52</td>
<td>Total TPS: 20045.18 <span style="background-color:lightgreen;">(+106.45%)</span><br>Mean TPOT(ms): 246.26</td>
</tr>
<tr>
<td><strong>Generation-Heavy Prompt</strong></td>
<td>Total TPS: 3112.52<br>Mean TPOT(ms): 45.72</td>
<td>Total TPS: 3703.98 <span style="background-color:lightgreen;">(+19.0%)</span><br>Mean TPOT(ms): 39.45</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ol>
<li>Our benchmark tests do not cover all possible optimization combinations. For example, we select the inference engine that performs best under its default configuration as the starting point for further tuning. This pruning approach yields a local optimum, which may not be the global optimum.</li>
<li>There are other optimization methods that depend on specific user scenarios, including max batch size, schedule configuration, extended KV cache, CUDA graph, etc. The conclusions in this document can serve as a starting point for more targeted optimizations.</li>
<li>The tests are conducted on specific hardware and software setups. Advances in the inference engine may lead to new conclusions.</li>
</ol>
</div>
<p>If there are any missing points or updates reflecting new changes, please <a href="https://github.com/gpustack/gpustack/issues/new/choose">let us know</a>.</p>
<h2 id="optimization-objective">Optimization Objective</h2>
<p>Achieve high throughput under high-concurrency request scenarios.</p>
<h2 id="experimental-setup">Experimental Setup</h2>
<h3 id="model">Model</h3>
<p>deepseek-ai/DeepSeek-V3.2</p>
<h3 id="hardware">Hardware</h3>
<p>8  NVIDIA H200 SXM GPUs on a single node.</p>
<h3 id="engine-version">Engine Version</h3>
<ul>
<li>vLLM: v0.13.0</li>
<li>SGLang: v0.5.6.post2</li>
<li>TensorRT-LLM: 1.2.0rc5</li>
</ul>
<h3 id="benchmark-dataset">Benchmark Dataset</h3>
<ol>
<li>ShareGPT</li>
<li>Random dataset with varying sequence lengths:<ul>
<li>Very long prompt: 32000 input tokens, 100 output tokens</li>
<li>Long prompt: 4000 input tokens, 200 output tokens</li>
<li>Medium prompt: 2000 input tokens, 100 output tokens</li>
<li>Short prompt: 128 input tokens, 4 output tokens</li>
<li>Generation-Heavy Prompt: 1K input tokens, 2K output tokens</li>
</ul>
</li>
</ol>
<h3 id="benchmark-script">Benchmark Script</h3>
<p>We use the <strong>vLLM bench CLI</strong> tool to benchmark the model performance. The following command is used to run the benchmark:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Prepare the ShareGPT dataset</span>
wget<span class="w"> </span>https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/resolve/main/ShareGPT_V3_unfiltered_cleaned_split.json

<span class="c1"># Benchmark on ShareGPT dataset</span>
vllm<span class="w"> </span>bench<span class="w"> </span>serve<span class="w"> </span>--model<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span>--backend<span class="w"> </span>openai-chat<span class="w"> </span>--endpoint<span class="w"> </span>/v1/chat/completions<span class="w"> </span>--dataset-name<span class="w"> </span>sharegpt<span class="w"> </span>--dataset-path<span class="w"> </span>ShareGPT_V3_unfiltered_cleaned_split.json<span class="w"> </span>--num-prompts<span class="w"> </span><span class="m">1000</span>

<span class="c1"># Benchmark on random dataset (fixed seed for reproducibility)</span>
vllm<span class="w"> </span>bench<span class="w"> </span>serve<span class="w"> </span>--model<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span>--backend<span class="w"> </span>openai-chat<span class="w"> </span>--endpoint<span class="w"> </span>/v1/chat/completions<span class="w"> </span>--dataset-name<span class="w"> </span>random<span class="w"> </span>--random-input-len<span class="w"> </span><span class="m">4000</span><span class="w"> </span>--random-output-len<span class="w"> </span><span class="m">200</span><span class="w"> </span>--num-prompts<span class="w"> </span><span class="m">500</span><span class="w"> </span>--seed<span class="w"> </span><span class="m">42</span>
</code></pre></div>
<h2 id="experiment-results">Experiment Results</h2>
<h3 id="1-baseline-of-the-inference-engine">1. Baseline of the Inference Engine</h3>
<p>vLLM</p>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code>vllm<span class="w"> </span>serve<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span>-tp<span class="w"> </span><span class="m">8</span><span class="w"> </span>--tokenizer-mode<span class="w"> </span>deepseek_v32<span class="w"> </span>--reasoning-parser<span class="w"> </span>deepseek_v3
</code></pre></div>
</details>
<details class="info">
<summary>Benchmark result</summary>
<div class="highlight"><pre><span></span><code>============ Serving Benchmark Result ============
Successful requests:                     1000
Benchmark duration (s):                  72.75
Total input tokens:                      219111
Total generated tokens:                  196599
Request throughput (req/s):              13.75
Output token throughput (tok/s):         2702.26
Peak output token throughput (tok/s):    6009.00
Peak concurrent requests:                1000.00
Total Token throughput (tok/s):          5713.95
---------------Time to First Token----------------
Mean TTFT (ms):                          13054.63
Median TTFT (ms):                        12849.39
P99 TTFT (ms):                           22754.42
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          275.03
Median TPOT (ms):                        171.63
P99 TPOT (ms):                           666.78
---------------Inter-token Latency----------------
Mean ITL (ms):                           131.14
Median ITL (ms):                         81.97
P99 ITL (ms):                            668.29
==================================================
</code></pre></div>
</details>
<p>SGLang</p>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code>python3<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model-path<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span>--host<span class="w"> </span><span class="m">0</span>.0.0.0<span class="w"> </span>--port<span class="w"> </span><span class="m">8000</span><span class="w"> </span><span class="se">\</span>
--chat-template<span class="w"> </span>./tool_chat_template_deepseekv32.jinja<span class="w"> </span><span class="se">\</span>
--tp-size<span class="w"> </span><span class="m">8</span>
</code></pre></div>
</details>
<details class="info">
<summary>Benchmark result</summary>
<div class="highlight"><pre><span></span><code>============ Serving Benchmark Result ============
Successful requests:                     1000
Benchmark duration (s):                  138.25
Total input tokens:                      219111
Total generated tokens:                  197337
Request throughput (req/s):              7.23
Output token throughput (tok/s):         1427.44
Peak output token throughput (tok/s):    7949.00
Peak concurrent requests:                1000.00
Total Token throughput (tok/s):          3012.37
---------------Time to First Token----------------
Mean TTFT (ms):                          11470.15
Median TTFT (ms):                        11240.35
P99 TTFT (ms):                           22363.90
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          1103.96
Median TPOT (ms):                        672.86
P99 TPOT (ms):                           4231.55
---------------Inter-token Latency----------------
Mean ITL (ms):                           389.06
Median ITL (ms):                         64.46
P99 ITL (ms):                            3013.62
==================================================
</code></pre></div>
</details>
<p>TensorRT-LLM</p>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code>trtllm-serve<span class="w"> </span>/workspace/DeepSeek-v3.2<span class="w"> </span>--tp_size<span class="w"> </span><span class="m">8</span>
</code></pre></div>
</details>
<details class="info">
<summary>Benchmark result</summary>
<div class="highlight"><pre><span></span><code>============ Serving Benchmark Result ============
Successful requests:                     984
Benchmark duration (s):                  236.70
Total input tokens:                      215176
Total generated tokens:                  194893
Request throughput (req/s):              4.16
Output token throughput (tok/s):         823.39
Peak output token throughput (tok/s):    4212.00
Peak concurrent requests:                984.00
Total Token throughput (tok/s):          1732.48
---------------Time to First Token----------------
Mean TTFT (ms):                          65710.22
Median TTFT (ms):                        66076.17
P99 TTFT (ms):                           125723.14
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          1391.76
Median TPOT (ms):                        608.74
P99 TPOT (ms):                           4785.14
---------------Inter-token Latency----------------
Mean ITL (ms):                           459.69
Median ITL (ms):                         141.56
P99 ITL (ms):                            4910.46
==================================================
</code></pre></div>
</details>
<p>Result: vLLM (5713.95 tok/s) &gt; SGLang(3012.37 tok/s) &gt; TensorRT-LLM (1732.48 tok/s)</p>
<h3 id="2-optimizing-vllm">2. Optimizing vLLM</h3>
<h4 id="parallelism-dpep">Parallelism: DP+EP</h4>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code><span class="c1"># 81920 is half context, full context OOM</span>
vllm<span class="w"> </span>serve<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span>--tokenizer-mode<span class="w"> </span>deepseek_v32<span class="w"> </span>--reasoning-parser<span class="w"> </span>deepseek_v3<span class="w"> </span><span class="se">\</span>
-tp<span class="w"> </span><span class="m">1</span><span class="w"> </span>-dp<span class="w"> </span><span class="m">8</span><span class="w"> </span>--enable-expert-parallel<span class="w"> </span>--max-model-len<span class="w"> </span><span class="m">81920</span>
</code></pre></div>
</details>
<details class="info">
<summary>Benchmark result</summary>
<div class="highlight"><pre><span></span><code>Successful requests:                     1000
Benchmark duration (s):                  65.62
Total input tokens:                      219111
Total generated tokens:                  197109
Request throughput (req/s):              15.24
Output token throughput (tok/s):         3003.90
Peak output token throughput (tok/s):    10222.00
Peak concurrent requests:                1000.00
Total Token throughput (tok/s):          6343.10
---------------Time to First Token----------------
Mean TTFT (ms):                          9144.24
Median TTFT (ms):                        10233.68
P99 TTFT (ms):                           14920.03
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          278.22
Median TPOT (ms):                        115.72
P99 TPOT (ms):                           2048.82
---------------Inter-token Latency----------------
Mean ITL (ms):                           100.47
Median ITL (ms):                         74.61
P99 ITL (ms):                            1239.62
==================================================
</code></pre></div>
</details>
<h4 id="parallelism-dcp">Parallelism: DCP</h4>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code>vllm<span class="w"> </span>serve<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span>-tp<span class="w"> </span><span class="m">8</span><span class="w"> </span>--tokenizer-mode<span class="w"> </span>deepseek_v32<span class="w"> </span>--reasoning-parser<span class="w"> </span>deepseek_v3<span class="w"> </span><span class="se">\</span>
-dcp<span class="w"> </span><span class="m">8</span>
</code></pre></div>
</details>
<p>DeepSeek V3.2 relies on the FlashMLA sparse attention backend, which currently does not expose softmax log-sum-exp (LSE) during the decode phase. Since Decode Context Parallelism (DCP) requires softmax LSE for correct cross-rank aggregation, DCP is not supported with FlashMLA at this time, leading to a runtime failure in vLLM. This limitation has been discussed in the vLLM repository (see issue <a href="https://github.com/vllm-project/vllm/issues/27544">#27544</a>).</p>
<h4 id="mtp">MTP</h4>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code>vllm<span class="w"> </span>serve<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span>-tp<span class="w"> </span><span class="m">8</span><span class="w"> </span>--tokenizer-mode<span class="w"> </span>deepseek_v32<span class="w"> </span>--reasoning-parser<span class="w"> </span>deepseek_v3<span class="w"> </span><span class="se">\</span>
--speculative-config<span class="w"> </span><span class="o">{</span><span class="s2">&quot;method&quot;</span>:<span class="s2">&quot;mtp&quot;</span>,<span class="s2">&quot;num_speculative_tokens&quot;</span>:1<span class="o">}</span>
</code></pre></div>
</details>
<details class="info">
<summary>Benchmark result</summary>
<div class="highlight"><pre><span></span><code>============ Serving Benchmark Result ============
Successful requests:                     1000
Benchmark duration (s):                  75.13
Total input tokens:                      219111
Total generated tokens:                  197345
Request throughput (req/s):              13.31
Output token throughput (tok/s):         2626.63
Peak output token throughput (tok/s):    3940.00
Peak concurrent requests:                1000.00
Total Token throughput (tok/s):          5542.96
---------------Time to First Token----------------
Mean TTFT (ms):                          11110.51
Median TTFT (ms):                        10739.31
P99 TTFT (ms):                           21886.92
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          291.48
Median TPOT (ms):                        250.14
P99 TPOT (ms):                           735.48
---------------Inter-token Latency----------------
Mean ITL (ms):                           290.48
Median ITL (ms):                         144.81
P99 ITL (ms):                            4636.00
==================================================
</code></pre></div>
</details>
<h4 id="turn-off-deepgemm-in-vllm">Turn off DeepGEMM in vLLM</h4>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code><span class="nb">export</span><span class="w"> </span><span class="nv">VLLM_USE_DEEP_GEMM</span><span class="o">=</span><span class="m">0</span>
vllm<span class="w"> </span>serve<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span>-tp<span class="w"> </span><span class="m">8</span><span class="w"> </span>--tokenizer-mode<span class="w"> </span>deepseek_v32<span class="w"> </span>--reasoning-parser<span class="w"> </span>deepseek_v3
</code></pre></div>
</details>
<details class="info">
<summary>Benchmark result</summary>
<div class="highlight"><pre><span></span><code>============ Serving Benchmark Result ============
Successful requests:                     1000
Benchmark duration (s):                  74.92
Total input tokens:                      219111
Total generated tokens:                  197222
Request throughput (req/s):              13.35
Output token throughput (tok/s):         2632.38
Peak output token throughput (tok/s):    6010.00
Peak concurrent requests:                1000.00
Total Token throughput (tok/s):          5556.92
---------------Time to First Token----------------
Mean TTFT (ms):                          11250.21
Median TTFT (ms):                        10762.25
P99 TTFT (ms):                           20723.94
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          287.49
Median TPOT (ms):                        188.99
P99 TPOT (ms):                           667.67
---------------Inter-token Latency----------------
Mean ITL (ms):                           140.98
Median ITL (ms):                         83.88
P99 ITL (ms):                            671.43
==================================================
</code></pre></div>
</details>
<h4 id="enable-tool-call-configuration">Enable Tool Call Configuration</h4>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code>vllm<span class="w"> </span>serve<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span>-tp<span class="w"> </span><span class="m">8</span><span class="w"> </span>--tokenizer-mode<span class="w"> </span>deepseek_v32<span class="w"> </span>--reasoning-parser<span class="w"> </span>deepseek_v3<span class="w"> </span>--tool-call-parser<span class="w"> </span>deepseek_v32<span class="w"> </span>--enable-auto-tool-choice
</code></pre></div>
</details>
<details class="info">
<summary>Benchmark result</summary>
<div class="highlight"><pre><span></span><code>============ Serving Benchmark Result ============
Successful requests:                     1000
Benchmark duration (s):                  74.16
Total input tokens:                      219111
Total generated tokens:                  197012
Request throughput (req/s):              13.48
Output token throughput (tok/s):         2656.40
Peak output token throughput (tok/s):    6095.00
Peak concurrent requests:                1000.00
Total Token throughput (tok/s):          5610.78
---------------Time to First Token----------------
Mean TTFT (ms):                          13648.83
Median TTFT (ms):                        13557.38
P99 TTFT (ms):                           23498.54
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          280.78
Median TPOT (ms):                        176.29
P99 TPOT (ms):                           677.36
---------------Inter-token Latency----------------
Mean ITL (ms):                           132.99
Median ITL (ms):                         82.69
P99 ITL (ms):                            683.11
==================================================
</code></pre></div>
</details>
<h4 id="context-length-adjustment">Context Length Adjustment</h4>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code>vllm<span class="w"> </span>serve<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span>-tp<span class="w"> </span><span class="m">8</span><span class="w"> </span>--tokenizer-mode<span class="w"> </span>deepseek_v32<span class="w"> </span>--reasoning-parser<span class="w"> </span>deepseek_v3<span class="w"> </span>--max-model-len<span class="w"> </span><span class="m">32768</span>
</code></pre></div>
</details>
<details class="info">
<summary>Benchmark result</summary>
<div class="highlight"><pre><span></span><code><span class="o">============</span><span class="w"> </span>Serving<span class="w"> </span>Benchmark<span class="w"> </span><span class="nv">Result</span><span class="w"> </span><span class="o">============</span>
Successful<span class="w"> </span>requests:<span class="w">                     </span><span class="m">1000</span>
Benchmark<span class="w"> </span>duration<span class="w"> </span><span class="o">(</span>s<span class="o">)</span>:<span class="w">                  </span><span class="m">75</span>.12
Total<span class="w"> </span>input<span class="w"> </span>tokens:<span class="w">                      </span><span class="m">219111</span>
Total<span class="w"> </span>generated<span class="w"> </span>tokens:<span class="w">                  </span><span class="m">196938</span>
Request<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>req/s<span class="o">)</span>:<span class="w">              </span><span class="m">13</span>.31
Output<span class="w"> </span>token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">         </span><span class="m">2621</span>.48
Peak<span class="w"> </span>output<span class="w"> </span>token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">    </span><span class="m">6293</span>.00
Peak<span class="w"> </span>concurrent<span class="w"> </span>requests:<span class="w">                </span><span class="m">1000</span>.00
Total<span class="w"> </span>Token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">          </span><span class="m">5538</span>.11
---------------Time<span class="w"> </span>to<span class="w"> </span>First<span class="w"> </span>Token----------------
Mean<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                          </span><span class="m">10439</span>.14
Median<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                        </span><span class="m">10296</span>.60
P99<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">23842</span>.17
-----Time<span class="w"> </span>per<span class="w"> </span>Output<span class="w"> </span>Token<span class="w"> </span><span class="o">(</span>excl.<span class="w"> </span>1st<span class="w"> </span>token<span class="o">)</span>------
Mean<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                          </span><span class="m">357</span>.68
Median<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                        </span><span class="m">223</span>.35
P99<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">1169</span>.74
---------------Inter-token<span class="w"> </span>Latency----------------
Mean<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">154</span>.24
Median<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                         </span><span class="m">78</span>.13
P99<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                            </span><span class="m">660</span>.95
<span class="o">==================================================</span>
</code></pre></div>
</details>
<h4 id="attention-backend-cutlass_mla">Attention Backend: CUTLASS_MLA</h4>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code><span class="nb">export</span><span class="w"> </span><span class="nv">VLLM_ATTENTION_BACKEND</span><span class="o">=</span><span class="s2">&quot;CUTLASS_MLA&quot;</span>
vllm<span class="w"> </span>serve<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span>-tp<span class="w"> </span><span class="m">8</span><span class="w"> </span>--tokenizer-mode<span class="w"> </span>deepseek_v32<span class="w"> </span>--reasoning-parser<span class="w"> </span>deepseek_v3
</code></pre></div>
</details>
<p>ValueError: Selected backend AttentionBackendEnum.CUTLASS_MLA is not valid for this configuration. Reason: ['sparse not supported', 'compute capability not supported']</p>
<h4 id="attention-backend-flashmla">Attention Backend: FLASHMLA</h4>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code><span class="nb">export</span><span class="w"> </span><span class="nv">VLLM_ATTENTION_BACKEND</span><span class="o">=</span><span class="s2">&quot;FLASHMLA&quot;</span>
</code></pre></div>
</details>
<p>ValueError: Selected backend AttentionBackendEnum.FLASHMLA is not valid for this configuration. Reason: ['sparse not supported']</p>
<h4 id="attention-backend-triton_mla">Attention Backend: TRITON_MLA</h4>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code><span class="nb">export</span><span class="w"> </span><span class="nv">VLLM_ATTENTION_BACKEND</span><span class="o">=</span><span class="s2">&quot;TRITON_MLA&quot;</span>
vllm<span class="w"> </span>serve<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span>-tp<span class="w"> </span><span class="m">8</span><span class="w"> </span>--tokenizer-mode<span class="w"> </span>deepseek_v32<span class="w"> </span>--reasoning-parser<span class="w"> </span>deepseek_v3
</code></pre></div>
</details>
<p>ValueError: Selected backend AttentionBackendEnum.TRITON_MLA is not valid for this configuration. Reason: ['sparse not supported']</p>
<h3 id="3-optimizing-sglang">3. Optimizing SGLang</h3>
<h4 id="parallelism-tpdp-attention">Parallelism: TP+DP Attention</h4>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code>python3<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model-path<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span>--host<span class="w"> </span><span class="m">0</span>.0.0.0<span class="w"> </span>--port<span class="w"> </span><span class="m">8000</span><span class="w"> </span><span class="se">\</span>
--chat-template<span class="w"> </span>./tool_chat_template_deepseekv32.jinja<span class="w"> </span><span class="se">\</span>
--tp-size<span class="w"> </span><span class="m">8</span><span class="w"> </span>--enable-dp-attention
</code></pre></div>
</details>
<details class="info">
<summary>Benchmark result</summary>
<div class="highlight"><pre><span></span><code>============ Serving Benchmark Result ============
Successful requests:                     1000
Benchmark duration (s):                  99.46
Total input tokens:                      219111
Total generated tokens:                  197633
Request throughput (req/s):              10.05
Output token throughput (tok/s):         1987.11
Peak output token throughput (tok/s):    8911.00
Peak concurrent requests:                1000.00
Total Token throughput (tok/s):          4190.17
---------------Time to First Token----------------
Mean TTFT (ms):                          13679.11
Median TTFT (ms):                        12663.74
P99 TTFT (ms):                           21665.97
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          608.90
Median TPOT (ms):                        398.19
P99 TPOT (ms):                           3453.39
---------------Inter-token Latency----------------
Mean ITL (ms):                           230.03
Median ITL (ms):                         59.95
P99 ITL (ms):                            1824.84
==================================================
</code></pre></div>
</details>
<h4 id="parallelism-tpdpdp-attention">Parallelism: TP+DP+DP Attention</h4>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code>python3<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model-path<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span>--host<span class="w"> </span><span class="m">0</span>.0.0.0<span class="w"> </span>--port<span class="w"> </span><span class="m">8000</span><span class="w"> </span><span class="se">\</span>
--chat-template<span class="w"> </span>./tool_chat_template_deepseekv32.jinja<span class="w"> </span><span class="se">\</span>
--tp-size<span class="w"> </span><span class="m">8</span><span class="w"> </span>--dp-size<span class="w"> </span><span class="m">8</span><span class="w"> </span>--enable-dp-attention
</code></pre></div>
</details>
<details class="info">
<summary>Benchmark result</summary>
<div class="highlight"><pre><span></span><code>============ Serving Benchmark Result ============
Successful requests:                     1000
Benchmark duration (s):                  56.62
Total input tokens:                      219111
Total generated tokens:                  197116
Request throughput (req/s):              17.66
Output token throughput (tok/s):         3481.55
Peak output token throughput (tok/s):    11298.00
Peak concurrent requests:                1000.00
Total Token throughput (tok/s):          7351.59
---------------Time to First Token----------------
Mean TTFT (ms):                          7815.00
Median TTFT (ms):                        8024.81
P99 TTFT (ms):                           12928.46
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          287.86
Median TPOT (ms):                        107.58
P99 TPOT (ms):                           2096.18
---------------Inter-token Latency----------------
Mean ITL (ms):                           91.68
Median ITL (ms):                         58.87
P99 ITL (ms):                            317.43
==================================================
</code></pre></div>
</details>
<h4 id="parallelism-tpdpdp-attentionep">Parallelism: TP+DP+DP Attention+EP</h4>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code>python3<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model-path<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span>--host<span class="w"> </span><span class="m">0</span>.0.0.0<span class="w"> </span>--port<span class="w"> </span><span class="m">8000</span><span class="w"> </span><span class="se">\</span>
--chat-template<span class="w"> </span>./tool_chat_template_deepseekv32.jinja<span class="w"> </span><span class="se">\</span>
--tp-size<span class="w"> </span><span class="m">8</span><span class="w"> </span>--dp-size<span class="w"> </span><span class="m">8</span><span class="w"> </span>--enable-dp-attention<span class="w"> </span>--ep-size<span class="w"> </span><span class="m">8</span>
</code></pre></div>
</details>
<details class="info">
<summary>Benchmark result</summary>
<div class="highlight"><pre><span></span><code>============ Serving Benchmark Result ============
Successful requests:                     1000
Benchmark duration (s):                  57.14
Total input tokens:                      219111
Total generated tokens:                  197614
Request throughput (req/s):              17.50
Output token throughput (tok/s):         3458.68
Peak output token throughput (tok/s):    11757.00
Peak concurrent requests:                1000.00
Total Token throughput (tok/s):          7293.61
---------------Time to First Token----------------
Mean TTFT (ms):                          8437.36
Median TTFT (ms):                        8346.50
P99 TTFT (ms):                           15410.07
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          319.46
Median TPOT (ms):                        111.65
P99 TPOT (ms):                           2443.91
---------------Inter-token Latency----------------
Mean ITL (ms):                           94.48
Median ITL (ms):                         56.54
P99 ITL (ms):                            451.92
==================================================
</code></pre></div>
</details>
<h4 id="mtp_1">MTP</h4>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code>python3<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model-path<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span>--host<span class="w"> </span><span class="m">0</span>.0.0.0<span class="w"> </span>--port<span class="w"> </span><span class="m">8000</span><span class="w"> </span><span class="se">\</span>
--tp-size<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
--speculative-algorithm<span class="w"> </span>EAGLE<span class="w"> </span>--speculative-num-steps<span class="w"> </span><span class="m">1</span><span class="w"> </span>--speculative-eagle-topk<span class="w"> </span><span class="m">1</span><span class="w"> </span>--speculative-num-draft-tokens<span class="w"> </span><span class="m">2</span>
</code></pre></div>
</details>
<details class="info">
<summary>Benchmark result</summary>
<div class="highlight"><pre><span></span><code>============ Serving Benchmark Result ============
Successful requests:                     1000
Benchmark duration (s):                  278.36
Total input tokens:                      219111
Total generated tokens:                  193349
Request throughput (req/s):              3.59
Output token throughput (tok/s):         694.61
Peak output token throughput (tok/s):    974.00
Peak concurrent requests:                1000.00
Total Token throughput (tok/s):          1481.77
---------------Time to First Token----------------
Mean TTFT (ms):                          139046.94
Median TTFT (ms):                        144733.94
P99 TTFT (ms):                           260932.68
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          68.88
Median TPOT (ms):                        63.31
P99 TPOT (ms):                           280.02
---------------Inter-token Latency----------------
Mean ITL (ms):                           115.50
Median ITL (ms):                         48.42
P99 ITL (ms):                            337.68
==================================================
</code></pre></div>
</details>
<h4 id="turn-off-deepgemm">Turn off DeepGEMM</h4>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code><span class="nb">export</span><span class="w"> </span><span class="nv">SGLANG_ENABLE_JIT_DEEPGEMM</span><span class="o">=</span><span class="m">0</span>
python3<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model-path<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span>--host<span class="w"> </span><span class="m">0</span>.0.0.0<span class="w"> </span>--port<span class="w"> </span><span class="m">8000</span><span class="w"> </span><span class="se">\</span>
--chat-template<span class="w"> </span>./tool_chat_template_deepseekv32.jinja<span class="w"> </span><span class="se">\</span>
--tp-size<span class="w"> </span><span class="m">8</span>
</code></pre></div>
</details>
<p>The server fails to start when DeepGEMM is disabled.</p>
<h4 id="enable-tool-call-configuration_1">Enable Tool Call Configuration</h4>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code>python3<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model-path<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span>--host<span class="w"> </span><span class="m">0</span>.0.0.0<span class="w"> </span>--port<span class="w"> </span><span class="m">8000</span><span class="w"> </span><span class="se">\</span>
--chat-template<span class="w"> </span>./tool_chat_template_deepseekv32.jinja<span class="w"> </span><span class="se">\</span>
--tp-size<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
--enable-dp-attention<span class="w"> </span><span class="se">\</span>
--dp<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
--reasoning-parser<span class="w"> </span>deepseek-v3<span class="w"> </span><span class="se">\</span>
--tool-call-parser<span class="w"> </span>deepseekv32
</code></pre></div>
</details>
<details class="info">
<summary>Benchmark result</summary>
<div class="highlight"><pre><span></span><code>============ Serving Benchmark Result ============
Successful requests:                     1000
Benchmark duration (s):                  49.70
Total input tokens:                      219111
Total generated tokens:                  197192
Request throughput (req/s):              20.12
Output token throughput (tok/s):         3967.70
Peak output token throughput (tok/s):    13083.00
Peak concurrent requests:                1000.00
Total Token throughput (tok/s):          8376.43
---------------Time to First Token----------------
Mean TTFT (ms):                          6577.70
Median TTFT (ms):                        6815.18
P99 TTFT (ms):                           11936.83
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          250.64
Median TPOT (ms):                        95.20
P99 TPOT (ms):                           1825.45
---------------Inter-token Latency----------------
Mean ITL (ms):                           81.42
Median ITL (ms):                         53.51
P99 ITL (ms):                            269.50
==================================================
</code></pre></div>
</details>
<h4 id="context-length-adjustment_1">Context Length Adjustment</h4>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code>python3<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model-path<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span>--host<span class="w"> </span><span class="m">0</span>.0.0.0<span class="w"> </span>--port<span class="w"> </span><span class="m">8000</span><span class="w"> </span><span class="se">\</span>
--chat-template<span class="w"> </span>./tool_chat_template_deepseekv32.jinja<span class="w"> </span><span class="se">\</span>
--tp-size<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
--enable-dp-attention<span class="w"> </span><span class="se">\</span>
--dp<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
--reasoning-parser<span class="w"> </span>deepseek-v3<span class="w"> </span><span class="se">\</span>
--tool-call-parser<span class="w"> </span>deepseekv32<span class="w"> </span><span class="se">\</span>
--context-length<span class="o">=</span><span class="m">32768</span>
</code></pre></div>
</details>
<details class="info">
<summary>Benchmark result</summary>
<div class="highlight"><pre><span></span><code>============ Serving Benchmark Result ============
Successful requests:                     1000
Benchmark duration (s):                  47.60
Total input tokens:                      219111
Total generated tokens:                  197380
Request throughput (req/s):              21.01
Output token throughput (tok/s):         4146.96
Peak output token throughput (tok/s):    12798.00
Peak concurrent requests:                1000.00
Total Token throughput (tok/s):          8750.49
---------------Time to First Token----------------
Mean TTFT (ms):                          5615.34
Median TTFT (ms):                        5448.81
P99 TTFT (ms):                           10053.28
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          214.05
Median TPOT (ms):                        87.57
P99 TPOT (ms):                           1553.18
---------------Inter-token Latency----------------
Mean ITL (ms):                           76.04
Median ITL (ms):                         54.16
P99 ITL (ms):                            210.36
==================================================
</code></pre></div>
</details>
<h4 id="kv-cache-dtype">KV Cache DType</h4>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code>python3<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model-path<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span>--host<span class="w"> </span><span class="m">0</span>.0.0.0<span class="w"> </span>--port<span class="w"> </span><span class="m">8000</span><span class="w"> </span><span class="se">\</span>
--chat-template<span class="w"> </span>./tool_chat_template_deepseekv32.jinja<span class="w"> </span><span class="se">\</span>
--tp-size<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
--enable-dp-attention<span class="w"> </span><span class="se">\</span>
--dp<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
--reasoning-parser<span class="w"> </span>deepseek-v3<span class="w"> </span><span class="se">\</span>
--tool-call-parser<span class="w"> </span>deepseekv32<span class="w"> </span><span class="se">\</span>
--context-length<span class="o">=</span><span class="m">32768</span><span class="w"> </span><span class="se">\</span>
--kv-cache-dtype<span class="w"> </span>fp8_e4m3
</code></pre></div>
</details>
<details class="info">
<summary>Benchmark result</summary>
<div class="highlight"><pre><span></span><code>============ Serving Benchmark Result ============
Successful requests:                     1000
Benchmark duration (s):                  49.00
Total input tokens:                      219111
Total generated tokens:                  197078
Request throughput (req/s):              20.41
Output token throughput (tok/s):         4022.27
Peak output token throughput (tok/s):    12674.00
Peak concurrent requests:                1000.00
Total Token throughput (tok/s):          8494.23
---------------Time to First Token----------------
Mean TTFT (ms):                          5472.04
Median TTFT (ms):                        5289.41
P99 TTFT (ms):                           9731.02
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          213.50
Median TPOT (ms):                        92.04
P99 TPOT (ms):                           1471.85
---------------Inter-token Latency----------------
Mean ITL (ms):                           79.15
Median ITL (ms):                         58.50
P99 ITL (ms):                            100.53
==================================================
</code></pre></div>
</details>
<h4 id="attention-backend-fa3-fa3">Attention Backend: fa3 + fa3</h4>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code>python3<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model-path<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span>--host<span class="w"> </span><span class="m">0</span>.0.0.0<span class="w"> </span>--port<span class="w"> </span><span class="m">8000</span><span class="w"> </span><span class="se">\</span>
--chat-template<span class="w"> </span>./tool_chat_template_deepseekv32.jinja<span class="w"> </span><span class="se">\</span>
--tp-size<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
--enable-dp-attention<span class="w"> </span><span class="se">\</span>
--dp<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
--reasoning-parser<span class="w"> </span>deepseek-v3<span class="w"> </span><span class="se">\</span>
--tool-call-parser<span class="w"> </span>deepseekv32<span class="w"> </span><span class="se">\</span>
--context-length<span class="o">=</span><span class="m">32768</span><span class="w"> </span><span class="se">\</span>
--attention-backend<span class="w"> </span>nsa<span class="w"> </span><span class="se">\</span>
--nsa-prefill-backend<span class="w"> </span>fa3<span class="w"> </span><span class="se">\</span>
--nsa-decode-backend<span class="w"> </span>fa3
</code></pre></div>
</details>
<details class="info">
<summary>Benchmark result</summary>
<div class="highlight"><pre><span></span><code>============ Serving Benchmark Result ============
Successful requests:                     1000
Benchmark duration (s):                  46.37
Total input tokens:                      219111
Total generated tokens:                  196786
Request throughput (req/s):              21.56
Output token throughput (tok/s):         4243.46
Peak output token throughput (tok/s):    13860.00
Peak concurrent requests:                1000.00
Total Token throughput (tok/s):          8968.32
---------------Time to First Token----------------
Mean TTFT (ms):                          5303.50
Median TTFT (ms):                        5145.47
P99 TTFT (ms):                           9366.93
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          203.05
Median TPOT (ms):                        85.23
P99 TPOT (ms):                           1399.48
---------------Inter-token Latency----------------
Mean ITL (ms):                           74.03
Median ITL (ms):                         53.86
P99 ITL (ms):                            177.03
==================================================
</code></pre></div>
</details>
<h4 id="attention-backend-flashmla_sparse-flashmla_kv">Attention Backend: flashmla_sparse + flashmla_kv</h4>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code>python3<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model-path<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span>--host<span class="w"> </span><span class="m">0</span>.0.0.0<span class="w"> </span>--port<span class="w"> </span><span class="m">8000</span><span class="w"> </span><span class="se">\</span>
--chat-template<span class="w"> </span>./tool_chat_template_deepseekv32.jinja<span class="w"> </span><span class="se">\</span>
--tp-size<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
--enable-dp-attention<span class="w"> </span><span class="se">\</span>
--dp<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
--reasoning-parser<span class="w"> </span>deepseek-v3<span class="w"> </span><span class="se">\</span>
--tool-call-parser<span class="w"> </span>deepseekv32<span class="w"> </span><span class="se">\</span>
--context-length<span class="o">=</span><span class="m">32768</span><span class="w"> </span><span class="se">\</span>
--attention-backend<span class="w"> </span>nsa<span class="w"> </span><span class="se">\</span>
--nsa-prefill-backend<span class="w"> </span>flashmla_sparse<span class="w"> </span><span class="se">\</span>
--nsa-decode-backend<span class="w"> </span>flashmla_kv
</code></pre></div>
</details>
<details class="info">
<summary>Benchmark result</summary>
<div class="highlight"><pre><span></span><code>============ Serving Benchmark Result ============
Successful requests:                     1000
Benchmark duration (s):                  77.68
Total input tokens:                      219111
Total generated tokens:                  197443
Request throughput (req/s):              12.87
Output token throughput (tok/s):         2541.62
Peak output token throughput (tok/s):    8352.00
Peak concurrent requests:                1000.00
Total Token throughput (tok/s):          5362.16
---------------Time to First Token----------------
Mean TTFT (ms):                          4811.25
Median TTFT (ms):                        4727.17
P99 TTFT (ms):                           9086.60
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          260.25
Median TPOT (ms):                        128.33
P99 TPOT (ms):                           1625.53
---------------Inter-token Latency----------------
Mean ITL (ms):                           114.47
Median ITL (ms):                         91.44
P99 ITL (ms):                            256.14
==================================================
</code></pre></div>
</details>
<h3 id="4-optimizing-tensorrt-llm">4. Optimizing TensorRT-LLM</h3>
<h4 id="parallelism-tpep">Parallelism: TP+EP</h4>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code>trtllm-serve<span class="w"> </span>/workspace/DeepSeek-v3.2<span class="w"> </span>--tp_size<span class="w"> </span><span class="m">8</span><span class="w"> </span>--ep_size<span class="w"> </span><span class="m">8</span><span class="w"> </span>--pp_size<span class="w"> </span><span class="m">1</span>
</code></pre></div>
</details>
<details class="info">
<summary>Benchmark result</summary>
<div class="highlight"><pre><span></span><code>============ Serving Benchmark Result ============
Successful requests:                     984
Benchmark duration (s):                  142.99
Total input tokens:                      216405
Total generated tokens:                  195740
Request throughput (req/s):              6.88
Output token throughput (tok/s):         1368.90
Peak output token throughput (tok/s):    4635.00
Peak concurrent requests:                984.00
Total Token throughput (tok/s):          2882.32
---------------Time to First Token----------------
Mean TTFT (ms):                          24155.45
Median TTFT (ms):                        23945.42
P99 TTFT (ms):                           45683.09
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          561.24
Median TPOT (ms):                        312.75
P99 TPOT (ms):                           1473.03
---------------Inter-token Latency----------------
Mean ITL (ms):                           248.40
Median ITL (ms):                         142.18
P99 ITL (ms):                            1819.83
==================================================
</code></pre></div>
</details>
<h4 id="turn-off-deepgemm_1">Turn off DeepGEMM</h4>
<details class="info">
<summary>Serving script</summary>
<div class="highlight"><pre><span></span><code><span class="nb">export</span><span class="w"> </span><span class="nv">TRTLLM_DG_ENABLED</span><span class="o">=</span><span class="m">0</span>
trtllm-serve<span class="w"> </span>/workspace/DeepSeek-v3.2<span class="w"> </span>--tp_size<span class="w"> </span><span class="m">8</span><span class="w"> </span>--ep_size<span class="w"> </span><span class="m">8</span><span class="w"> </span>--pp_size<span class="w"> </span><span class="m">1</span>
</code></pre></div>
</details>
<details class="info">
<summary>Benchmark result</summary>
<div class="highlight"><pre><span></span><code>============ Serving Benchmark Result ============
Successful requests:                     984
Benchmark duration (s):                  134.65
Total input tokens:                      216484
Total generated tokens:                  194509
Request throughput (req/s):              7.31
Output token throughput (tok/s):         1444.56
Peak output token throughput (tok/s):    4661.00
Peak concurrent requests:                984.00
Total Token throughput (tok/s):          3052.33
---------------Time to First Token----------------
Mean TTFT (ms):                          23229.65
Median TTFT (ms):                        23100.28
P99 TTFT (ms):                           44648.94
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          541.07
Median TPOT (ms):                        264.04
P99 TPOT (ms):                           1588.04
---------------Inter-token Latency----------------
Mean ITL (ms):                           226.30
Median ITL (ms):                         137.80
P99 ITL (ms):                            1624.47
==================================================
</code></pre></div>
</details>
<h3 id="summary-of-optimization-options">Summary of Optimization Options</h3>
<table>
<thead>
<tr>
<th>Optimization Option</th>
<th>Throughput Improvement</th>
</tr>
</thead>
<tbody>
<tr>
<td>Parallelism</td>
<td><span style="background-color:lightgreen;">+28.66%</span></td>
</tr>
<tr>
<td>Tool Call Configuration</td>
<td><span style="background-color:lightgreen;">+13.94%</span></td>
</tr>
<tr>
<td>Context Length Adjust</td>
<td><span style="background-color:lightgreen;">+4.47%</span></td>
</tr>
<tr>
<td>Attention Backend</td>
<td><span style="background-color:lightgreen;">+2.49%</span></td>
</tr>
<tr>
<td>KV Cache Dtype</td>
<td>-</td>
</tr>
<tr>
<td>MTP</td>
<td>-</td>
</tr>
<tr>
<td>DeepGEMM</td>
<td>-</td>
</tr>
<tr>
<td>Total(vs Baseline)</td>
<td><span style="background-color:lightgreen;">+56.97%</span></td>
</tr>
</tbody>
</table>
<h3 id="other-benchmark-cases">Other Benchmark Cases</h3>
<p>We further benchmarked the optimized configuration to evaluate its generalization under various workloads.</p>
<details class="info">
<summary>Baseline serving script</summary>
<div class="highlight"><pre><span></span><code>vllm<span class="w"> </span>serve<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span>-tp<span class="w"> </span><span class="m">8</span><span class="w"> </span>--tokenizer-mode<span class="w"> </span>deepseek_v32<span class="w"> </span>--reasoning-parser<span class="w"> </span>deepseek_v3
</code></pre></div>
</details>
<details class="info">
<summary>Baseline benchmark results</summary>
<div class="highlight"><pre><span></span><code><span class="c1"># random 128 input</span>
<span class="o">============</span><span class="w"> </span>Serving<span class="w"> </span>Benchmark<span class="w"> </span><span class="nv">Result</span><span class="w"> </span><span class="o">============</span>
Successful<span class="w"> </span>requests:<span class="w">                     </span><span class="m">1000</span>
Benchmark<span class="w"> </span>duration<span class="w"> </span><span class="o">(</span>s<span class="o">)</span>:<span class="w">                  </span><span class="m">13</span>.11
Total<span class="w"> </span>input<span class="w"> </span>tokens:<span class="w">                      </span><span class="m">128000</span>
Total<span class="w"> </span>generated<span class="w"> </span>tokens:<span class="w">                  </span><span class="m">4000</span>
Request<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>req/s<span class="o">)</span>:<span class="w">              </span><span class="m">76</span>.30
Output<span class="w"> </span>token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">         </span><span class="m">305</span>.20
Peak<span class="w"> </span>output<span class="w"> </span>token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">    </span><span class="m">1029</span>.00
Peak<span class="w"> </span>concurrent<span class="w"> </span>requests:<span class="w">                </span><span class="m">1000</span>.00
Total<span class="w"> </span>Token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">          </span><span class="m">10071</span>.49
---------------Time<span class="w"> </span>to<span class="w"> </span>First<span class="w"> </span>Token----------------
Mean<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                          </span><span class="m">5786</span>.15
Median<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                        </span><span class="m">4666</span>.02
P99<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">12922</span>.46
-----Time<span class="w"> </span>per<span class="w"> </span>Output<span class="w"> </span>Token<span class="w"> </span><span class="o">(</span>excl.<span class="w"> </span>1st<span class="w"> </span>token<span class="o">)</span>------
Mean<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                          </span><span class="m">781</span>.80
Median<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                        </span><span class="m">687</span>.63
P99<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">1637</span>.52
---------------Inter-token<span class="w"> </span>Latency----------------
Mean<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">586</span>.79
Median<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                         </span><span class="m">664</span>.73
P99<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                            </span><span class="m">3545</span>.51
<span class="o">==================================================</span>


<span class="c1"># random 2K input</span>
<span class="o">============</span><span class="w"> </span>Serving<span class="w"> </span>Benchmark<span class="w"> </span><span class="nv">Result</span><span class="w"> </span><span class="o">============</span>
Successful<span class="w"> </span>requests:<span class="w">                     </span><span class="m">500</span>
Benchmark<span class="w"> </span>duration<span class="w"> </span><span class="o">(</span>s<span class="o">)</span>:<span class="w">                  </span><span class="m">96</span>.10
Total<span class="w"> </span>input<span class="w"> </span>tokens:<span class="w">                      </span><span class="m">1000000</span>
Total<span class="w"> </span>generated<span class="w"> </span>tokens:<span class="w">                  </span><span class="m">50000</span>
Request<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>req/s<span class="o">)</span>:<span class="w">              </span><span class="m">5</span>.20
Output<span class="w"> </span>token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">         </span><span class="m">520</span>.27
Peak<span class="w"> </span>output<span class="w"> </span>token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">    </span><span class="m">4085</span>.00
Peak<span class="w"> </span>concurrent<span class="w"> </span>requests:<span class="w">                </span><span class="m">500</span>.00
Total<span class="w"> </span>Token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">          </span><span class="m">10925</span>.59
---------------Time<span class="w"> </span>to<span class="w"> </span>First<span class="w"> </span>Token----------------
Mean<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                          </span><span class="m">45667</span>.57
Median<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                        </span><span class="m">43997</span>.53
P99<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">87384</span>.57
-----Time<span class="w"> </span>per<span class="w"> </span>Output<span class="w"> </span>Token<span class="w"> </span><span class="o">(</span>excl.<span class="w"> </span>1st<span class="w"> </span>token<span class="o">)</span>------
Mean<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                          </span><span class="m">354</span>.59
Median<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                        </span><span class="m">433</span>.59
P99<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">452</span>.30
---------------Inter-token<span class="w"> </span>Latency----------------
Mean<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">353</span>.26
Median<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                         </span><span class="m">68</span>.59
P99<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                            </span><span class="m">661</span>.87
<span class="o">==================================================</span>


<span class="c1"># random 4K input</span>
<span class="o">============</span><span class="w"> </span>Serving<span class="w"> </span>Benchmark<span class="w"> </span><span class="nv">Result</span><span class="w"> </span><span class="o">============</span>
Successful<span class="w"> </span>requests:<span class="w">                     </span><span class="m">500</span>
Benchmark<span class="w"> </span>duration<span class="w"> </span><span class="o">(</span>s<span class="o">)</span>:<span class="w">                  </span><span class="m">210</span>.54
Total<span class="w"> </span>input<span class="w"> </span>tokens:<span class="w">                      </span><span class="m">2000000</span>
Total<span class="w"> </span>generated<span class="w"> </span>tokens:<span class="w">                  </span><span class="m">100000</span>
Request<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>req/s<span class="o">)</span>:<span class="w">              </span><span class="m">2</span>.37
Output<span class="w"> </span>token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">         </span><span class="m">474</span>.96
Peak<span class="w"> </span>output<span class="w"> </span>token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">    </span><span class="m">2769</span>.00
Peak<span class="w"> </span>concurrent<span class="w"> </span>requests:<span class="w">                </span><span class="m">500</span>.00
Total<span class="w"> </span>Token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">          </span><span class="m">9974</span>.26
---------------Time<span class="w"> </span>to<span class="w"> </span>First<span class="w"> </span>Token----------------
Mean<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                          </span><span class="m">103386</span>.88
Median<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                        </span><span class="m">97324</span>.68
P99<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">200514</span>.23
-----Time<span class="w"> </span>per<span class="w"> </span>Output<span class="w"> </span>Token<span class="w"> </span><span class="o">(</span>excl.<span class="w"> </span>1st<span class="w"> </span>token<span class="o">)</span>------
Mean<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                          </span><span class="m">226</span>.74
Median<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                        </span><span class="m">246</span>.98
P99<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">275</span>.68
---------------Inter-token<span class="w"> </span>Latency----------------
Mean<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">228</span>.79
Median<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                         </span><span class="m">49</span>.50
P99<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                            </span><span class="m">683</span>.63
<span class="o">==================================================</span>


<span class="c1"># random 32k input</span>
<span class="o">============</span><span class="w"> </span>Serving<span class="w"> </span>Benchmark<span class="w"> </span><span class="nv">Result</span><span class="w"> </span><span class="o">============</span>
Successful<span class="w"> </span>requests:<span class="w">                     </span><span class="m">100</span>
Benchmark<span class="w"> </span>duration<span class="w"> </span><span class="o">(</span>s<span class="o">)</span>:<span class="w">                  </span><span class="m">330</span>.61
Total<span class="w"> </span>input<span class="w"> </span>tokens:<span class="w">                      </span><span class="m">3200000</span>
Total<span class="w"> </span>generated<span class="w"> </span>tokens:<span class="w">                  </span><span class="m">10000</span>
Request<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>req/s<span class="o">)</span>:<span class="w">              </span><span class="m">0</span>.30
Output<span class="w"> </span>token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">         </span><span class="m">30</span>.25
Peak<span class="w"> </span>output<span class="w"> </span>token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">    </span><span class="m">384</span>.00
Peak<span class="w"> </span>concurrent<span class="w"> </span>requests:<span class="w">                </span><span class="m">100</span>.00
Total<span class="w"> </span>Token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">          </span><span class="m">9709</span>.27
---------------Time<span class="w"> </span>to<span class="w"> </span>First<span class="w"> </span>Token----------------
Mean<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                          </span><span class="m">164003</span>.81
Median<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                        </span><span class="m">164174</span>.93
P99<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">325134</span>.01
-----Time<span class="w"> </span>per<span class="w"> </span>Output<span class="w"> </span>Token<span class="w"> </span><span class="o">(</span>excl.<span class="w"> </span>1st<span class="w"> </span>token<span class="o">)</span>------
Mean<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                          </span><span class="m">472</span>.52
Median<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                        </span><span class="m">512</span>.36
P99<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">514</span>.39
---------------Inter-token<span class="w"> </span>Latency----------------
Mean<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">477</span>.69
Median<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                         </span><span class="m">741</span>.90
P99<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                            </span><span class="m">949</span>.57
<span class="o">==================================================</span>


1k<span class="w"> </span>random<span class="w"> </span>input<span class="w"> </span>+<span class="w"> </span>2k<span class="w"> </span><span class="nv">generation</span>
<span class="o">============</span><span class="w"> </span>Serving<span class="w"> </span>Benchmark<span class="w"> </span><span class="nv">Result</span><span class="w"> </span><span class="o">============</span>
Successful<span class="w"> </span>requests:<span class="w">                     </span><span class="m">100</span>
Benchmark<span class="w"> </span>duration<span class="w"> </span><span class="o">(</span>s<span class="o">)</span>:<span class="w">                  </span><span class="m">96</span>.39
Total<span class="w"> </span>input<span class="w"> </span>tokens:<span class="w">                      </span><span class="m">100000</span>
Total<span class="w"> </span>generated<span class="w"> </span>tokens:<span class="w">                  </span><span class="m">200000</span>
Request<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>req/s<span class="o">)</span>:<span class="w">              </span><span class="m">1</span>.04
Output<span class="w"> </span>token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">         </span><span class="m">2075</span>.01
Peak<span class="w"> </span>output<span class="w"> </span>token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">    </span><span class="m">2598</span>.00
Peak<span class="w"> </span>concurrent<span class="w"> </span>requests:<span class="w">                </span><span class="m">100</span>.00
Total<span class="w"> </span>Token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">          </span><span class="m">3112</span>.52
---------------Time<span class="w"> </span>to<span class="w"> </span>First<span class="w"> </span>Token----------------
Mean<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                          </span><span class="m">4789</span>.20
Median<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                        </span><span class="m">4590</span>.83
P99<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">10608</span>.88
-----Time<span class="w"> </span>per<span class="w"> </span>Output<span class="w"> </span>Token<span class="w"> </span><span class="o">(</span>excl.<span class="w"> </span>1st<span class="w"> </span>token<span class="o">)</span>------
Mean<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                          </span><span class="m">45</span>.72
Median<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                        </span><span class="m">45</span>.83
P99<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">47</span>.44
---------------Inter-token<span class="w"> </span>Latency----------------
Mean<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">46</span>.34
Median<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                         </span><span class="m">43</span>.13
P99<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                            </span><span class="m">44</span>.29
<span class="o">==================================================</span>
</code></pre></div>
</details>
<details class="info">
<summary>Optimized serving script</summary>
<div class="highlight"><pre><span></span><code>python3<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model<span class="w"> </span>deepseek-ai/DeepSeek-V3.2<span class="w"> </span><span class="se">\</span>
--chat-template<span class="w"> </span>./tool_chat_template_deepseekv32.jinja<span class="w"> </span><span class="se">\</span>
--tp-size<span class="w"> </span><span class="m">8</span><span class="w"> </span>--dp-size<span class="w"> </span><span class="m">8</span><span class="w"> </span>--enable-dp-attention<span class="w"> </span><span class="se">\</span>
--reasoning-parser<span class="w"> </span>deepseek-v3<span class="w"> </span><span class="se">\</span>
--tool-call-parser<span class="w"> </span>deepseekv32<span class="w"> </span><span class="se">\</span>
--context-length<span class="o">=</span><span class="m">32768</span><span class="w"> </span><span class="se">\</span>
--attention-backend<span class="w"> </span>nsa<span class="w"> </span><span class="se">\</span>
--nsa-prefill-backend<span class="w"> </span>fa3<span class="w"> </span><span class="se">\</span>
--nsa-decode-backend<span class="w"> </span>fa3
</code></pre></div>
</details>
<details class="info">
<summary>Optimized benchmark results</summary>
<div class="highlight"><pre><span></span><code><span class="c1"># random 128 input</span>
<span class="o">============</span><span class="w"> </span>Serving<span class="w"> </span>Benchmark<span class="w"> </span><span class="nv">Result</span><span class="w"> </span><span class="o">============</span>
Successful<span class="w"> </span>requests:<span class="w">                     </span><span class="m">984</span>
Benchmark<span class="w"> </span>duration<span class="w"> </span><span class="o">(</span>s<span class="o">)</span>:<span class="w">                  </span><span class="m">7</span>.13
Total<span class="w"> </span>input<span class="w"> </span>tokens:<span class="w">                      </span><span class="m">125952</span>
Total<span class="w"> </span>generated<span class="w"> </span>tokens:<span class="w">                  </span><span class="m">3936</span>
Request<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>req/s<span class="o">)</span>:<span class="w">              </span><span class="m">138</span>.09
Output<span class="w"> </span>token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">         </span><span class="m">552</span>.34
Peak<span class="w"> </span>output<span class="w"> </span>token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">    </span><span class="m">2526</span>.00
Peak<span class="w"> </span>concurrent<span class="w"> </span>requests:<span class="w">                </span><span class="m">984</span>.00
Total<span class="w"> </span>Token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">          </span><span class="m">18227</span>.38
---------------Time<span class="w"> </span>to<span class="w"> </span>First<span class="w"> </span>Token----------------
Mean<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                          </span><span class="m">4441</span>.81
Median<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                        </span><span class="m">4685</span>.89
P99<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">6735</span>.22
-----Time<span class="w"> </span>per<span class="w"> </span>Output<span class="w"> </span>Token<span class="w"> </span><span class="o">(</span>excl.<span class="w"> </span>1st<span class="w"> </span>token<span class="o">)</span>------
Mean<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                          </span><span class="m">776</span>.55
Median<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                        </span><span class="m">714</span>.97
P99<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">1659</span>.07
---------------Inter-token<span class="w"> </span>Latency----------------
Mean<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">465</span>.93
Median<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                         </span><span class="m">59</span>.97
P99<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                            </span><span class="m">4564</span>.16
<span class="o">==================================================</span>


<span class="c1"># random 2K input</span>
<span class="o">============</span><span class="w"> </span>Serving<span class="w"> </span>Benchmark<span class="w"> </span><span class="nv">Result</span><span class="w"> </span><span class="o">============</span>
Successful<span class="w"> </span>requests:<span class="w">                     </span><span class="m">500</span>
Benchmark<span class="w"> </span>duration<span class="w"> </span><span class="o">(</span>s<span class="o">)</span>:<span class="w">                  </span><span class="m">37</span>.89
Total<span class="w"> </span>input<span class="w"> </span>tokens:<span class="w">                      </span><span class="m">1000000</span>
Total<span class="w"> </span>generated<span class="w"> </span>tokens:<span class="w">                  </span><span class="m">50000</span>
Request<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>req/s<span class="o">)</span>:<span class="w">              </span><span class="m">13</span>.20
Output<span class="w"> </span>token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">         </span><span class="m">1319</span>.64
Peak<span class="w"> </span>output<span class="w"> </span>token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">    </span><span class="m">9477</span>.00
Peak<span class="w"> </span>concurrent<span class="w"> </span>requests:<span class="w">                </span><span class="m">500</span>.00
Total<span class="w"> </span>Token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">          </span><span class="m">27712</span>.54
---------------Time<span class="w"> </span>to<span class="w"> </span>First<span class="w"> </span>Token----------------
Mean<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                          </span><span class="m">18696</span>.78
Median<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                        </span><span class="m">18939</span>.89
P99<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">32138</span>.14
-----Time<span class="w"> </span>per<span class="w"> </span>Output<span class="w"> </span>Token<span class="w"> </span><span class="o">(</span>excl.<span class="w"> </span>1st<span class="w"> </span>token<span class="o">)</span>------
Mean<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                          </span><span class="m">192</span>.24
Median<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                        </span><span class="m">189</span>.20
P99<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">349</span>.96
---------------Inter-token<span class="w"> </span>Latency----------------
Mean<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">189</span>.18
Median<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                         </span><span class="m">55</span>.05
P99<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                            </span><span class="m">219</span>.74
<span class="o">==================================================</span>


<span class="c1"># random 4K input</span>
<span class="o">============</span><span class="w"> </span>Serving<span class="w"> </span>Benchmark<span class="w"> </span><span class="nv">Result</span><span class="w"> </span><span class="o">============</span>
Successful<span class="w"> </span>requests:<span class="w">                     </span><span class="m">500</span>
Benchmark<span class="w"> </span>duration<span class="w"> </span><span class="o">(</span>s<span class="o">)</span>:<span class="w">                  </span><span class="m">102</span>.21
Total<span class="w"> </span>input<span class="w"> </span>tokens:<span class="w">                      </span><span class="m">2000000</span>
Total<span class="w"> </span>generated<span class="w"> </span>tokens:<span class="w">                  </span><span class="m">100000</span>
Request<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>req/s<span class="o">)</span>:<span class="w">              </span><span class="m">4</span>.89
Output<span class="w"> </span>token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">         </span><span class="m">978</span>.37
Peak<span class="w"> </span>output<span class="w"> </span>token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">    </span><span class="m">7180</span>.00
Peak<span class="w"> </span>concurrent<span class="w"> </span>requests:<span class="w">                </span><span class="m">500</span>.00
Total<span class="w"> </span>Token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">          </span><span class="m">20545</span>.67
---------------Time<span class="w"> </span>to<span class="w"> </span>First<span class="w"> </span>Token----------------
Mean<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                          </span><span class="m">44019</span>.81
Median<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                        </span><span class="m">40806</span>.24
P99<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">90171</span>.38
-----Time<span class="w"> </span>per<span class="w"> </span>Output<span class="w"> </span>Token<span class="w"> </span><span class="o">(</span>excl.<span class="w"> </span>1st<span class="w"> </span>token<span class="o">)</span>------
Mean<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                          </span><span class="m">177</span>.95
Median<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                        </span><span class="m">161</span>.14
P99<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">321</span>.10
---------------Inter-token<span class="w"> </span>Latency----------------
Mean<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">177</span>.57
Median<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                         </span><span class="m">49</span>.55
P99<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                            </span><span class="m">224</span>.52
<span class="o">==================================================</span>


<span class="c1"># random 32k input</span>
<span class="o">============</span><span class="w"> </span>Serving<span class="w"> </span>Benchmark<span class="w"> </span><span class="nv">Result</span><span class="w"> </span><span class="o">============</span>
Successful<span class="w"> </span>requests:<span class="w">                     </span><span class="m">100</span>
Benchmark<span class="w"> </span>duration<span class="w"> </span><span class="o">(</span>s<span class="o">)</span>:<span class="w">                  </span><span class="m">160</span>.14
Total<span class="w"> </span>input<span class="w"> </span>tokens:<span class="w">                      </span><span class="m">3200000</span>
Total<span class="w"> </span>generated<span class="w"> </span>tokens:<span class="w">                  </span><span class="m">10000</span>
Request<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>req/s<span class="o">)</span>:<span class="w">              </span><span class="m">0</span>.62
Output<span class="w"> </span>token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">         </span><span class="m">62</span>.45
Peak<span class="w"> </span>output<span class="w"> </span>token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">    </span><span class="m">1189</span>.00
Peak<span class="w"> </span>concurrent<span class="w"> </span>requests:<span class="w">                </span><span class="m">100</span>.00
Total<span class="w"> </span>Token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">          </span><span class="m">20045</span>.18
---------------Time<span class="w"> </span>to<span class="w"> </span>First<span class="w"> </span>Token----------------
Mean<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                          </span><span class="m">83964</span>.72
Median<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                        </span><span class="m">88265</span>.70
P99<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">157005</span>.30
-----Time<span class="w"> </span>per<span class="w"> </span>Output<span class="w"> </span>Token<span class="w"> </span><span class="o">(</span>excl.<span class="w"> </span>1st<span class="w"> </span>token<span class="o">)</span>------
Mean<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                          </span><span class="m">246</span>.26
Median<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                        </span><span class="m">229</span>.67
P99<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">514</span>.42
---------------Inter-token<span class="w"> </span>Latency----------------
Mean<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">244</span>.63
Median<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                         </span><span class="m">33</span>.21
P99<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                            </span><span class="m">898</span>.58
<span class="o">==================================================</span>


1k<span class="w"> </span>random<span class="w"> </span>input<span class="w"> </span>+<span class="w"> </span>2k<span class="w"> </span><span class="nv">generation</span>
<span class="o">============</span><span class="w"> </span>Serving<span class="w"> </span>Benchmark<span class="w"> </span><span class="nv">Result</span><span class="w"> </span><span class="o">============</span>
Successful<span class="w"> </span>requests:<span class="w">                     </span><span class="m">100</span>
Benchmark<span class="w"> </span>duration<span class="w"> </span><span class="o">(</span>s<span class="o">)</span>:<span class="w">                  </span><span class="m">80</span>.99
Total<span class="w"> </span>input<span class="w"> </span>tokens:<span class="w">                      </span><span class="m">100000</span>
Total<span class="w"> </span>generated<span class="w"> </span>tokens:<span class="w">                  </span><span class="m">200000</span>
Request<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>req/s<span class="o">)</span>:<span class="w">              </span><span class="m">1</span>.23
Output<span class="w"> </span>token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">         </span><span class="m">2469</span>.32
Peak<span class="w"> </span>output<span class="w"> </span>token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">    </span><span class="m">2800</span>.00
Peak<span class="w"> </span>concurrent<span class="w"> </span>requests:<span class="w">                </span><span class="m">100</span>.00
Total<span class="w"> </span>Token<span class="w"> </span>throughput<span class="w"> </span><span class="o">(</span>tok/s<span class="o">)</span>:<span class="w">          </span><span class="m">3703</span>.98
---------------Time<span class="w"> </span>to<span class="w"> </span>First<span class="w"> </span>Token----------------
Mean<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                          </span><span class="m">2103</span>.54
Median<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                        </span><span class="m">2216</span>.52
P99<span class="w"> </span>TTFT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">3514</span>.77
-----Time<span class="w"> </span>per<span class="w"> </span>Output<span class="w"> </span>Token<span class="w"> </span><span class="o">(</span>excl.<span class="w"> </span>1st<span class="w"> </span>token<span class="o">)</span>------
Mean<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                          </span><span class="m">39</span>.45
Median<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                        </span><span class="m">39</span>.40
P99<span class="w"> </span>TPOT<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">40</span>.17
---------------Inter-token<span class="w"> </span>Latency----------------
Mean<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                           </span><span class="m">40</span>.56
Median<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                         </span><span class="m">38</span>.90
P99<span class="w"> </span>ITL<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w">                            </span><span class="m">43</span>.63
<span class="o">==================================================</span>
</code></pre></div>
</details>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["search.suggest", "search.highlight", "content.tabs.link", "navigation.indexes", "content.tooltips", "navigation.path", "navigation.tabs", "content.code.annotate", "content.code.copy", "content.code.select", "content.action.view", "content.action.edit"], "search": "../../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.fe8b6f2b.min.js"></script>
      
        <script src="../../../javascripts/katex.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/katex.min.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/contrib/auto-render.min.js"></script>
      
    
  <script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body>
</html>